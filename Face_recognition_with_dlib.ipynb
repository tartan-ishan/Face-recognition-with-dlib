{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db34c2d-2500-402b-afd2-f5e39258ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f33a257-d0ae-4237-bb3b-d67024f6ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf9cc529-0837-48ee-99e7-a6ab66d5c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a6943d5-ae62-4c57-bcd4-f9669990e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba56be8b-04f1-4109-a2c6-7838b6370d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize image in folder as requried\n",
    "# img = Image.open('bill_face_og.jpg')\n",
    "# img.thumbnail((360,480))\n",
    "# img.save('bill_face.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c6d9866-d017-4c86-9b55-1685e50cad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\Trident\\Desktop\\Code\\player_images\"\n",
    "in_name = 'ishan.jpg'\n",
    "out_name = 'ishan_resized.jpg'\n",
    "resize_image(file_path, in_name, out_name, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86388bb6-0884-4c4d-a290-ad6d822fbffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(path,img_in, img_out, max_dim):\n",
    "    img = Image.open(f'{path}\\\\{img_in}')\n",
    "    img.thumbnail((max_dim,max_dim))\n",
    "    img.save(f'{path}\\\\{img_out}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f042d7c5-c6a9-46b2-b719-dc3753038729",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = face_recognition.load_image_file('bill_face.jpg')\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ecd6cd5-6093-427b-8519-2444cd6b4c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "face = face_recognition.face_locations(img_rgb, model='cnn')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a85352b0-c299-4b07-a4b1-843bddb157ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = img_rgb.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41a30a77-7334-457a-979a-c06c504418c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.rectangle(copy, (face[0], face[1]), (face[2], face[3]), (0,0,255), 2)\n",
    "cv2.imshow('copy', copy)\n",
    "cv2.imshow('face', img_rgb)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbe8449a-f31a-4e42-a55e-263ca6e5a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encode = face_recognition.face_encodings(img_rgb)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f58364e8-1bb7-4d7a-bc4d-d4de0a839ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = [train_encode, train_encode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e51a3d38-941f-496f-a047-f304bf97420f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True]\n"
     ]
    }
   ],
   "source": [
    "test = face_recognition.load_image_file('bill_face_3.jpg')\n",
    "test_rgb = cv2.cvtColor(test, cv2.COLOR_BGR2RGB)\n",
    "test_encode = face_recognition.face_encodings(test_rgb)[0]\n",
    "print(face_recognition.compare_faces(train_encodings, test_encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97dfc876-2121-4747-9dfd-9738dbe8e224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get an averaged result for face match vs input array\n",
    "res = [1,0,0,1,1,1,1,1,1,1,1]\n",
    "round(np.mean(res),2) > 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfb22777-6d66-4279-b062-981b72f4eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0242bd29-9313-4da3-951d-104a93c0a788",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'player_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f58b593e-256e-4303-baeb-8055fba13df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "classNames = []\n",
    "mylist = os.listdir(path)\n",
    "for player in mylist:\n",
    "    curImg = cv2.imread(f'{path}/{player}')\n",
    "    images.append(curImg)\n",
    "    classNames.append(os.path.splitext(player)[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4018743e-b12c-4dba-83e4-0a5054e6415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3d02c9c-4c2f-4013-af29-a60ba1daec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findEncodings(image):\n",
    "    encodeList = []\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encoded_face = face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encoded_face)\n",
    "    return encodeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "001263a7-dd14-42ef-89ee-af2ca0a1cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To encode faces from the sample images\n",
    "encoded_face_train = findEncodings(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e9150e8-4efe-428d-96ef-dc1bae9635e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To open and update \n",
    "def register_name(name):\n",
    "    with open('Registered_Names.csv', 'r+') as f:\n",
    "        myDataList = f.readlines()\n",
    "        nameList = []\n",
    "        for line in myDataList:\n",
    "            entry = line.split(',')\n",
    "            nameList.append(entry[0])\n",
    "        if name not in nameList:\n",
    "            now = datetime.now()\n",
    "            time = now.strftime('%I:%M:%S:%p')\n",
    "            date = now.strftime('%d-%B-%Y')\n",
    "            f.writelines(f'{name}, {time}, {date}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218d4fc2-67e9-4848-bfe2-78301c330b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap  = cv2.VideoCapture(0)    # take pictures from webcam \n",
    "s = 4    # Image rescaling factor\n",
    "\n",
    "while True:\n",
    "    time.sleep(0.01)    # To avoid jittery frames and improce general accuracy at the cost of output fps \n",
    "    success, img = cap.read()\n",
    "    imgS = cv2.resize(img, (0,0), None, 1/s ,1/s)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "    faces_in_frame = face_recognition.face_locations(imgS)\n",
    "    encoded_faces = face_recognition.face_encodings(imgS, faces_in_frame)\n",
    "    \n",
    "    for encode_face, faceloc in zip(encoded_faces,faces_in_frame):\n",
    "        #To only perform the coparison and recognition when the *spacebar* is pressed on the keyboard \n",
    "        if cv2.waitKey(1) & 0xFF == ord(' '):     \n",
    "            matches = face_recognition.compare_faces(encoded_face_train, encode_face)\n",
    "            faceDist = face_recognition.face_distance(encoded_face_train, encode_face)\n",
    "            matchIndex = np.argmin(faceDist)\n",
    "            print(matchIndex, name)\n",
    "            \n",
    "            if matches[matchIndex]:\n",
    "                name = classNames[matchIndex].upper().lower()\n",
    "                y1,x2,y2,x1 = faceloc\n",
    "                # since we scaled down by 4 times\n",
    "                y1, x2,y2,x1 = y1*s,x2*s,y2*s,x1*s\n",
    "                cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "                cv2.rectangle(img, (x1,y2-35),(x2,y2), (0,255,0), cv2.FILLED)\n",
    "                cv2.putText(img,name, (x1+6,y2-5), cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
    "                register_name(name)\n",
    "    cv2.imshow('webcam', img)\n",
    "\n",
    "# To stop the recognition and break from the loop, press 'q' a couple of times \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# Inorder to properly close the windows opened to show the cap.read() output, we must use the following two commands\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb1c91e-f6ea-4660-a35b-506a6694a856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7357e9c-75e4-4f43-807d-cc88fd5440eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d68331-7a4d-48b3-808b-54db6531e065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
